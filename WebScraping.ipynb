{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0cc9be4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Names of Group Members: Hayden Johnson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17a188b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a746379b",
   "metadata": {},
   "source": [
    "# Q1.) Web Crawling Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9c053e",
   "metadata": {},
   "source": [
    "### Q1.A.) Create a list of links for all the wikipedia pages for NYSE traded companies A-Z and 0-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06210434",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lovely_soup(u):\n",
    "    page = requests.get(u)\n",
    "    return(BeautifulSoup(page.content, 'html.parser'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cacb8e3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stockURL = 'https://www.nyse.com/quote/XNYS:'\n",
    "URL = \"https://en.wikipedia.org/wiki/Companies_listed_on_the_New_York_Stock_Exchange_(A)\"\n",
    "baseURL = '/wiki/Companies_listed_on_the_New_York_Stock_Exchange_'\n",
    "soup = lovely_soup(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3fc3acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "wikiUrlList = []\n",
    "\n",
    "for a in soup.findAll(\"a\", href = True):\n",
    "    if baseURL in a['href']:\n",
    "        wikiUrlList.append('https://en.wikipedia.org/' + a[\"href\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d9ca8d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(A)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(A)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(A)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(0%E2%80%939)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(B)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(C)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(D)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(E)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(F)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(G)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(H)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(I)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(J)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(K)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(L)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(M)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(N)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(O)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(P)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(Q)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(R)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(S)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(T)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(U)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(V)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(W)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(X)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(Y)',\n",
       " 'https://en.wikipedia.org//wiki/Companies_listed_on_the_New_York_Stock_Exchange_(Z)']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wikiUrlList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "831d5ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "stockUrlList = []\n",
    "\n",
    "for a in soup.findAll(\"a\", href = True):\n",
    "    if stockURL in a['href']:\n",
    "        stockUrlList.append(a[\"href\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "32e44b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "allStockList = []\n",
    "for url in wikiUrlList:\n",
    "    soup = lovely_soup(url)\n",
    "\n",
    "    for a in soup.findAll(\"a\", href = True):\n",
    "        if stockURL in a['href']:\n",
    "            allStockList.append(a[\"href\"] )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efc32e3",
   "metadata": {},
   "source": [
    "### Q1.B.) Crawl through all the URLs and make 1 DF with all the NYSE publically traded companies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3e274b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = []\n",
    "for link in allStockList:\n",
    "    ticker = re.search('XNYS:(\\w+)', link).group(1)\n",
    "    tickers.append(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d8c9b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nyse = pd.DataFrame(allStockList, columns=['NYSE Links'])\n",
    "nyse['Ticker'] = tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33fdbfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NYSE Links</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.nyse.com/quote/XNYS:AOS</td>\n",
       "      <td>AOS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.nyse.com/quote/XNYS:ATEN</td>\n",
       "      <td>ATEN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.nyse.com/quote/XNYS:AAC</td>\n",
       "      <td>AAC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.nyse.com/quote/XNYS:AIR</td>\n",
       "      <td>AIR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.nyse.com/quote/XNYS:AAN</td>\n",
       "      <td>AAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3314</th>\n",
       "      <td>https://www.nyse.com/quote/XNYS:ZBH</td>\n",
       "      <td>ZBH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3315</th>\n",
       "      <td>https://www.nyse.com/quote/XNYS:ZION</td>\n",
       "      <td>ZION</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3316</th>\n",
       "      <td>https://www.nyse.com/quote/XNYS:ZUO</td>\n",
       "      <td>ZUO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3317</th>\n",
       "      <td>https://www.nyse.com/quote/XNYS:ZTS</td>\n",
       "      <td>ZTS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3318</th>\n",
       "      <td>https://www.nyse.com/quote/XNYS:ZYME</td>\n",
       "      <td>ZYME</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3319 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                NYSE Links Ticker\n",
       "0      https://www.nyse.com/quote/XNYS:AOS    AOS\n",
       "1     https://www.nyse.com/quote/XNYS:ATEN   ATEN\n",
       "2      https://www.nyse.com/quote/XNYS:AAC    AAC\n",
       "3      https://www.nyse.com/quote/XNYS:AIR    AIR\n",
       "4      https://www.nyse.com/quote/XNYS:AAN    AAN\n",
       "...                                    ...    ...\n",
       "3314   https://www.nyse.com/quote/XNYS:ZBH    ZBH\n",
       "3315  https://www.nyse.com/quote/XNYS:ZION   ZION\n",
       "3316   https://www.nyse.com/quote/XNYS:ZUO    ZUO\n",
       "3317   https://www.nyse.com/quote/XNYS:ZTS    ZTS\n",
       "3318  https://www.nyse.com/quote/XNYS:ZYME   ZYME\n",
       "\n",
       "[3319 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4290fd74",
   "metadata": {},
   "source": [
    "### Q1.C.) What is the percetages of companies that contain 1 letter, 2 letters, 3 letters, 4 letters and 5 letters in the ticker?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "498afb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "one = 0\n",
    "two = 0\n",
    "three = 0\n",
    "four = 0\n",
    "five = 0\n",
    "for ticker in nyse['Ticker']:\n",
    "    if len(ticker) == 1:\n",
    "        one += 1\n",
    "    elif len(ticker) == 2:\n",
    "        two += 1\n",
    "    elif len(ticker) == 3:\n",
    "        three += 1\n",
    "    elif len(ticker) == 4:\n",
    "        four += 1\n",
    "    elif len(ticker) == 5:\n",
    "        five += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e9af6842",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of companies with 1 letter ticker: 0.9038867128653209\n",
      "Percentage of companies with 2 letter ticker: 6.809279903585417\n",
      "Percentage of companies with 3 letter ticker: 64.35673395601084\n",
      "Percentage of companies with 4 letter ticker: 16.57125640253088\n",
      "Percentage of companies with 5 letter ticker: 9.731846941849955\n"
     ]
    }
   ],
   "source": [
    "print('Percentage of companies with 1 letter ticker:', (one/len(nyse))*100)\n",
    "print('Percentage of companies with 2 letter ticker:', (two/len(nyse))*100)\n",
    "print('Percentage of companies with 3 letter ticker:', (three/len(nyse))*100)\n",
    "print('Percentage of companies with 4 letter ticker:', (four/len(nyse))*100)\n",
    "print('Percentage of companies with 5 letter ticker:', (five/len(nyse))*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2ef18b",
   "metadata": {},
   "source": [
    "# Q2.) Web Scraping Using Beautiful Soup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf558ab0",
   "metadata": {},
   "source": [
    "### Q2.A.) Using Beautiful soup .findAll method you will webscrape the front page of Reddit. Get a list of all of the \"timestamps\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "486d042e",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://www.reddit.com\"\n",
    "soup = lovely_soup(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42be8589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['3 hours ago',\n",
       " '5 hours ago',\n",
       " '19 hours ago',\n",
       " '18 hours ago',\n",
       " '22 hours ago',\n",
       " '13 hours ago',\n",
       " '22 hours ago',\n",
       " '5 hours ago']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp = soup.findAll(\"span\",\n",
    "                     attrs = {\"data-click-id\":\"timestamp\"})\n",
    "cleanTime = [t.text for t in timestamp]\n",
    "cleanTime"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269d9855",
   "metadata": {},
   "source": [
    "### Q2.B.) Using the functions findChild, descendents, etc. locate the post title and store in a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0201a791",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['“When can I go back to school?”',\n",
       " 'AI is taking over',\n",
       " 'just wow',\n",
       " 'Pornhub Blocks All of Utah From Its Site',\n",
       " \"Guns turn cowardly men into psychopathic, posturing lunatics, and that's all there is to it.\",\n",
       " 'The Writers Guild of America is Officially On Strike',\n",
       " 'The death of a single celled organism. RIP',\n",
       " 'Australia changes to color television live on March 1, 1975']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "div = soup.div\n",
    "titles = []\n",
    "for child in div.descendants:\n",
    "    if child.name == 'h3':\n",
    "        titles.append(child.text)\n",
    "titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6115ce9",
   "metadata": {},
   "source": [
    "### Q2.C.) Create a dataframe that has the associated title and post time for each post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e0b791b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timestamp</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3 hours ago</th>\n",
       "      <td>“When can I go back to school?”</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 hours ago</th>\n",
       "      <td>AI is taking over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19 hours ago</th>\n",
       "      <td>just wow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18 hours ago</th>\n",
       "      <td>Pornhub Blocks All of Utah From Its Site</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22 hours ago</th>\n",
       "      <td>Guns turn cowardly men into psychopathic, post...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13 hours ago</th>\n",
       "      <td>The Writers Guild of America is Officially On ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22 hours ago</th>\n",
       "      <td>The death of a single celled organism. RIP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5 hours ago</th>\n",
       "      <td>Australia changes to color television live on ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                          Title\n",
       "Timestamp                                                      \n",
       "3 hours ago                     “When can I go back to school?”\n",
       "5 hours ago                                   AI is taking over\n",
       "19 hours ago                                           just wow\n",
       "18 hours ago           Pornhub Blocks All of Utah From Its Site\n",
       "22 hours ago  Guns turn cowardly men into psychopathic, post...\n",
       "13 hours ago  The Writers Guild of America is Officially On ...\n",
       "22 hours ago         The death of a single celled organism. RIP\n",
       "5 hours ago   Australia changes to color television live on ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit = {'Title': titles, 'Timestamp': cleanTime}\n",
    "reddit = pd.DataFrame(reddit)\n",
    "reddit.set_index('Timestamp', inplace=True)\n",
    "reddit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd92ff4f",
   "metadata": {},
   "source": [
    "# Q3.) RegEx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb63deb",
   "metadata": {},
   "source": [
    "### Q3.A.) Using RegEx, get all the urls of ladder faculty profiles for UCLA Economics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f85363",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://economics.ucla.edu/faculty/ladder\"\n",
    "soup = lovely_soup(URL)\n",
    "text = str(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d5ed935",
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = re.findall(\"https://economics.ucla.edu/person/[\\w-]+/\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "89900337",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://economics.ucla.edu/person/jinyong-hahn/',\n",
       " 'https://economics.ucla.edu/person/saki-bigio/',\n",
       " 'https://economics.ucla.edu/person/rosa-liliana-matzkin/',\n",
       " 'https://economics.ucla.edu/person/moritz-meyer-ter-vehn/',\n",
       " 'https://economics.ucla.edu/person/denis-chetverikov/',\n",
       " 'https://economics.ucla.edu/person/oleg-itskhoki/',\n",
       " 'https://economics.ucla.edu/person/dora-costa/',\n",
       " 'https://economics.ucla.edu/person/ichiro-obara/',\n",
       " 'https://economics.ucla.edu/person/yotam-shem-tov/',\n",
       " 'https://economics.ucla.edu/person/lee-e-ohanian/',\n",
       " 'https://economics.ucla.edu/person/juliana-londono-velez/',\n",
       " 'https://economics.ucla.edu/person/tomasz-sadzik/',\n",
       " 'https://economics.ucla.edu/person/bernardo-s-silveira/',\n",
       " 'https://economics.ucla.edu/person/hugo-hopenhayn/',\n",
       " 'https://economics.ucla.edu/person/alexander-bloedel/',\n",
       " 'https://economics.ucla.edu/person/martha-bailey/',\n",
       " 'https://economics.ucla.edu/person/martin-b-hackmann/',\n",
       " 'https://economics.ucla.edu/person/david-baqaee/',\n",
       " 'https://economics.ucla.edu/person/natalie-bau/',\n",
       " 'https://economics.ucla.edu/person/maurizio-mazzocco/',\n",
       " 'https://economics.ucla.edu/person/john-asker/',\n",
       " 'https://economics.ucla.edu/person/daniel-haanwinckel/',\n",
       " 'https://economics.ucla.edu/person/felipe-goncalves/',\n",
       " 'https://economics.ucla.edu/person/andrew-atkeson/',\n",
       " 'https://economics.ucla.edu/person/gary-d-hansen/',\n",
       " 'https://economics.ucla.edu/person/aaron-tornell/',\n",
       " 'https://economics.ucla.edu/person/andres-santos/',\n",
       " 'https://economics.ucla.edu/person/pierre-olivier-weill/',\n",
       " 'https://economics.ucla.edu/person/zhipeng-liao/',\n",
       " 'https://economics.ucla.edu/person/jonathan-vogel/',\n",
       " 'https://economics.ucla.edu/person/shuyang-sheng/',\n",
       " 'https://economics.ucla.edu/person/francois-geerolf/',\n",
       " 'https://economics.ucla.edu/person/michela-giorcelli/',\n",
       " 'https://economics.ucla.edu/person/pablo-fajgelbaum/',\n",
       " 'https://economics.ucla.edu/person/simon-board/',\n",
       " 'https://economics.ucla.edu/person/jay-lu/',\n",
       " 'https://economics.ucla.edu/person/william-r-zame/',\n",
       " 'https://economics.ucla.edu/person/michael-rubens/',\n",
       " 'https://economics.ucla.edu/person/will-rafey/',\n",
       " 'https://economics.ucla.edu/person/rodrigo-pinto/',\n",
       " 'https://economics.ucla.edu/person/till-von-wachter/',\n",
       " 'https://economics.ucla.edu/person/kathleen-mcgarry/',\n",
       " 'https://economics.ucla.edu/person/sule-ozler/',\n",
       " 'https://economics.ucla.edu/person/adriana-lleras-muney/',\n",
       " 'https://economics.ucla.edu/person/ariel-burstein/']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matches = [match for match in matches]\n",
    "matches = list(set(matches))\n",
    "matches"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "633e5c6f",
   "metadata": {},
   "source": [
    "### Q3.B.) Webcrawl the links from A and use RegEx to get all the emails and phone numbers of ladder faculty profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "789bb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = \"https://economics.ucla.edu/person/pierre-olivier-weill/\"\n",
    "soup = lovely_soup(URL)\n",
    "text = str(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "41af3230",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['(310) 794-1686',\n",
       " '(310) 825-5304',\n",
       " '(310) 825-6682',\n",
       " '(310) 825-7371',\n",
       " '(310) 825-9397',\n",
       " '(310) 825-0979',\n",
       " '(310) 825-8018',\n",
       " '(310) 794-5342',\n",
       " '(310) 794-7241',\n",
       " '(310) 825-5665',\n",
       " '(310) 825-0849',\n",
       " '(310) 825-2523',\n",
       " '(310) 206-8896',\n",
       " '(310) 825-4521',\n",
       " ' 310-869-0742',\n",
       " '(310) 825-4249',\n",
       " '(310) 206-9463',\n",
       " '(310) 825-7380',\n",
       " '(310) 206-2833',\n",
       " '(310) 206-6732',\n",
       " '(310) 825-3847',\n",
       " '(310) 206-6031',\n",
       " '(310) 794-7098',\n",
       " '(310) 794-6495',\n",
       " '(310) 794-5427',\n",
       " '(310) 825-1011',\n",
       " '(310) 825-3925']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneNumber = []\n",
    "\n",
    "pattern = re.compile(r'\\(?\\s?\\d{3}\\s?\\)?\\-?\\s?\\d{3}-\\d{4}')\n",
    "\n",
    "for url in matches:\n",
    "    soup = lovely_soup(url)\n",
    "    text = str(soup)\n",
    "\n",
    "    phone_numbers = pattern.findall(text)\n",
    "\n",
    "    phoneNumber.extend(phone_numbers)\n",
    "phoneNumber = list(set(phoneNumber))\n",
    "phoneNumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "29c9fcef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hahn@econ.ucla.edu',\n",
       " 'econchair@econ.ucla.edu',\n",
       " 'chair@econ.ucla.edu',\n",
       " 'sbigio@econ.ucla.edu',\n",
       " 'matzkin@econ.ucla.edu',\n",
       " 'mtv@econ.ucla.edu',\n",
       " 'chetverikov@econ.ucla.edu',\n",
       " 'itskhoki@econ.ucla.edu',\n",
       " 'costa@econ.ucla.edu',\n",
       " 'iobara@econ.ucla.edu',\n",
       " 'shemtov@econ.ucla.edu',\n",
       " 'ohanian@econ.ucla.edu',\n",
       " 'j.londonovelez@econ.ucla.edu',\n",
       " 'tsadzik@econ.ucla.edu',\n",
       " 'silveira@econ.ucla.edu',\n",
       " 'hopen@econ.ucla.edu',\n",
       " 'abloedel@econ.ucla.edu',\n",
       " 'marthabailey@ucla.edu',\n",
       " 'hackmann@econ.ucla.edu',\n",
       " 'baqaee@econ.ucla.edu',\n",
       " 'nbau@g.ucla.edu',\n",
       " 'mmazzocc@econ.ucla.edu',\n",
       " 'johnasker@econ.ucla.edu',\n",
       " 'haanwinckel@econ.ucla.edu',\n",
       " 'fgoncalves@econ.ucla.edu',\n",
       " 'andy@atkeson.net',\n",
       " 'ghansen@econ.ucla.edu',\n",
       " 'tornell@econ.ucla.edu',\n",
       " 'andres@econ.ucla.edu',\n",
       " 'poweill@econ.ucla.edu',\n",
       " 'zhipeng.liao@econ.ucla.edu',\n",
       " 'jvogel@econ.ucla.edu',\n",
       " 'ssheng@econ.ucla.edu',\n",
       " 'fgeerolf@econ.ucla.edu',\n",
       " 'mgiorcelli@econ.ucla.edu',\n",
       " 'pfajgelbaum@econ.ucla.edu',\n",
       " 'sboard@econ.ucla.edu',\n",
       " 'jay@econ.ucla.edu',\n",
       " 'zame@econ.ucla.edu',\n",
       " 'rafey@econ.ucla.edu',\n",
       " 'rodrig@econ.ucla.edu',\n",
       " 'tvwachter@econ.ucla.edu',\n",
       " 'mcgarry@ucla.edu',\n",
       " 'ozler@econ.ucla.edu',\n",
       " 'alleras@econ.ucla.edu',\n",
       " 'arielb@econ.ucla.edu']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails = []\n",
    "for url in matches:\n",
    "    soup = lovely_soup(url)\n",
    "    text = str(soup)\n",
    "    email = re.findall(r'mailto:(?!webmaster\\b)([\\w.+%-]+@[\\w.-]+\\.[A-Za-z]+)', text)\n",
    "    \n",
    "    emails.extend(email)\n",
    "\n",
    "emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "effefb68",
   "metadata": {},
   "source": [
    "# Q4.) Selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d571a9c",
   "metadata": {},
   "source": [
    "### Q4.A.) Pick a website that has useful data to a business or economic question. Put your website you plan to scrape here : https://docs.google.com/spreadsheets/d/1yZTCktXhj7vT40HsITRQI_9FFZ-QIovSv4UZP9w67iI/edit?usp=sharing\n",
    "### You must have use website that no other group has. First come first serve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "f0c78096",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.swimcloud.com/times/?dont_group=false&event=150&gender=M&page=1&region=countryorganisation_usacollege&season_id=26'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6cc26fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "PATH = \"/Users/haydenjohnson00/Desktop/Drivers/chromedriver_mac_arm64/chromedriver\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4c70a577",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73399b19",
   "metadata": {},
   "source": [
    "### Q4.B.) Use Selenium to scrape valuable information from your website and store in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "48a89758",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collegeSwimming(event):\n",
    "    import time\n",
    "    options = webdriver.ChromeOptions()\n",
    "    options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(PATH, options = options)\n",
    "    driver.get(\"https://www.swimcloud.com/times/?dont_group=false&event=150&gender=M&page=1&region=countryorganisation_usacollege&season_id=26\")\n",
    "    #Navigate dropdown menu\n",
    "    dropdown = driver.find_element(By.ID, 'select_1')\n",
    "    select = Select(dropdown)\n",
    "    select.select_by_visible_text(event)\n",
    "    time.sleep(3)\n",
    "    #Swimmer Name\n",
    "    swimmer_names = []\n",
    "    nameLinks = driver.find_elements(By.CSS_SELECTOR, 'a[href^=\"/swimmer/\"]')\n",
    "    for link in nameLinks:\n",
    "        name = link.text\n",
    "        swimmer_names.append(name)\n",
    "    #Team\n",
    "    team_titles = []\n",
    "    teamLinks = driver.find_elements(By.CSS_SELECTOR, 'a[href^=\"/team/\"]')\n",
    "    for link in teamLinks:\n",
    "        title = link.get_attribute('title')\n",
    "        team_titles.append(title)\n",
    "    team_titles = list(filter(None, team_titles))\n",
    "    #Time\n",
    "    times = []\n",
    "    timeLinks = driver.find_elements(By.CSS_SELECTOR, 'a[href^=\"/results/\"]')\n",
    "    for link in timeLinks:\n",
    "        time = link.text\n",
    "        times.append(time)\n",
    "\n",
    "        cleanTimes = []\n",
    "\n",
    "    for element in times:\n",
    "        match = re.search(r'^\\d*:?\\d+\\.\\d+$', element)\n",
    "        if match:\n",
    "            cleanTimes.append(match.group(0))\n",
    "    #Make Dataframe\n",
    "    df = {'Swimmer': swimmer_names, 'Team': team_titles, 'Time': cleanTimes}\n",
    "    df = pd.DataFrame(df)\n",
    "    \n",
    "    driver.quit()\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "34fbbba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/qcpt_8pd5hlbv9w9cb71by8r0000gn/T/ipykernel_19026/286428583.py:5: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver = webdriver.Chrome(PATH, options = options)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Swimmer</th>\n",
       "      <th>Team</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>David Johnston</td>\n",
       "      <td>University of Texas</td>\n",
       "      <td>8:41.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Will Gallant</td>\n",
       "      <td>North Carolina State University</td>\n",
       "      <td>8:44.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ross Dant</td>\n",
       "      <td>North Carolina State University</td>\n",
       "      <td>8:46.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Charlie Clark</td>\n",
       "      <td>Ohio State University</td>\n",
       "      <td>8:48.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Levi Sandidge</td>\n",
       "      <td>University of Kentucky</td>\n",
       "      <td>8:48.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Zalán Sarkany</td>\n",
       "      <td>Arizona State University</td>\n",
       "      <td>8:49.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Luke Hobson</td>\n",
       "      <td>University of Texas</td>\n",
       "      <td>8:50.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Alec Enyeart</td>\n",
       "      <td>University of Texas</td>\n",
       "      <td>8:50.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Tyler Watson</td>\n",
       "      <td>University of Florida</td>\n",
       "      <td>8:50.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mason Mathias</td>\n",
       "      <td>Auburn University</td>\n",
       "      <td>8:51.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Kilavuz MERT</td>\n",
       "      <td>Georgia Institute of Technology</td>\n",
       "      <td>8:51.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Adam Wu</td>\n",
       "      <td>Columbia University</td>\n",
       "      <td>8:51.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Jack Hoagland</td>\n",
       "      <td>University of Notre Dame</td>\n",
       "      <td>8:52.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Alfonso Mestre</td>\n",
       "      <td>University of Florida</td>\n",
       "      <td>8:52.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jake Magahey</td>\n",
       "      <td>University of Georgia</td>\n",
       "      <td>8:53.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>James Plage</td>\n",
       "      <td>North Carolina State University</td>\n",
       "      <td>8:53.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Nick Caruso</td>\n",
       "      <td>University of Kentucky</td>\n",
       "      <td>8:53.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Cole Kuster</td>\n",
       "      <td>Harvard University</td>\n",
       "      <td>8:54.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Daniel Matheson</td>\n",
       "      <td>Arizona State University</td>\n",
       "      <td>8:54.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Bar Soloveychik</td>\n",
       "      <td>University of Minnesota</td>\n",
       "      <td>8:54.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>John Ehling</td>\n",
       "      <td>Princeton University</td>\n",
       "      <td>8:54.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sasha Lyubavskiy</td>\n",
       "      <td>University of Texas</td>\n",
       "      <td>8:55.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Lucas Henveaux</td>\n",
       "      <td>University of California-Berkeley</td>\n",
       "      <td>8:55.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Eric Brown</td>\n",
       "      <td>University of Florida</td>\n",
       "      <td>8:55.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Victor JOHANSSON</td>\n",
       "      <td>University of Alabama</td>\n",
       "      <td>8:55.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Cedric BUESSING</td>\n",
       "      <td>University of Indianapolis</td>\n",
       "      <td>8:55.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Hayden Curley</td>\n",
       "      <td>University of Tampa</td>\n",
       "      <td>8:56.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Eduardo Cisternas</td>\n",
       "      <td>Pennsylvania State University</td>\n",
       "      <td>8:56.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Owen Lloyd</td>\n",
       "      <td>North Carolina State University</td>\n",
       "      <td>8:56.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Victor Rosado</td>\n",
       "      <td>Oklahoma Christian University</td>\n",
       "      <td>8:56.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Dylan Robert Porges Avila</td>\n",
       "      <td>Princeton University</td>\n",
       "      <td>8:57.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Jack Little</td>\n",
       "      <td>University of Tennessee</td>\n",
       "      <td>8:57.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Gio Linscheer</td>\n",
       "      <td>University of Florida</td>\n",
       "      <td>8:57.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Jake Mitchell</td>\n",
       "      <td>University of Florida</td>\n",
       "      <td>8:57.74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Alex Zettle</td>\n",
       "      <td>University of Texas</td>\n",
       "      <td>8:57.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Mason Edmund</td>\n",
       "      <td>Ohio State University</td>\n",
       "      <td>8:59.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Brice Barrieault</td>\n",
       "      <td>U.S. Military Academy (Army)</td>\n",
       "      <td>8:59.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Rafael Nicolas Ponce De Leon</td>\n",
       "      <td>University of Tennessee</td>\n",
       "      <td>8:59.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Brennan Gravley</td>\n",
       "      <td>University of Florida</td>\n",
       "      <td>8:59.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ILIA SIBIRTSEV</td>\n",
       "      <td>University of Louisville</td>\n",
       "      <td>8:59.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Michael Bonson</td>\n",
       "      <td>Auburn University</td>\n",
       "      <td>9:00.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Grant Davis</td>\n",
       "      <td>Auburn University</td>\n",
       "      <td>9:00.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>Aidan Wilson</td>\n",
       "      <td>Brown University</td>\n",
       "      <td>9:00.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>Mark Kovacsics</td>\n",
       "      <td>California Baptist University</td>\n",
       "      <td>9:00.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>Jack VanDeusen</td>\n",
       "      <td>University of Florida</td>\n",
       "      <td>9:00.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>Gabe MACHADO</td>\n",
       "      <td>Stanford University</td>\n",
       "      <td>9:00.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>Eric Hieber</td>\n",
       "      <td>Grand Valley State University</td>\n",
       "      <td>9:00.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Oskar Lindholm</td>\n",
       "      <td>University of Florida</td>\n",
       "      <td>9:00.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>Jake Mason</td>\n",
       "      <td>Arizona State University</td>\n",
       "      <td>9:00.79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Jake Narvid</td>\n",
       "      <td>University of Tennessee</td>\n",
       "      <td>9:01.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Swimmer                               Team     Time\n",
       "0                 David Johnston                University of Texas  8:41.61\n",
       "1                   Will Gallant    North Carolina State University  8:44.48\n",
       "2                      Ross Dant    North Carolina State University  8:46.90\n",
       "3                  Charlie Clark              Ohio State University  8:48.61\n",
       "4                  Levi Sandidge             University of Kentucky  8:48.68\n",
       "5                  Zalán Sarkany           Arizona State University  8:49.31\n",
       "6                    Luke Hobson                University of Texas  8:50.10\n",
       "7                   Alec Enyeart                University of Texas  8:50.62\n",
       "8                   Tyler Watson              University of Florida  8:50.78\n",
       "9                  Mason Mathias                  Auburn University  8:51.45\n",
       "10                  Kilavuz MERT    Georgia Institute of Technology  8:51.61\n",
       "11                       Adam Wu                Columbia University  8:51.64\n",
       "12                 Jack Hoagland           University of Notre Dame  8:52.09\n",
       "13                Alfonso Mestre              University of Florida  8:52.27\n",
       "14                  Jake Magahey              University of Georgia  8:53.16\n",
       "15                   James Plage    North Carolina State University  8:53.27\n",
       "16                   Nick Caruso             University of Kentucky  8:53.74\n",
       "17                   Cole Kuster                 Harvard University  8:54.25\n",
       "18               Daniel Matheson           Arizona State University  8:54.66\n",
       "19               Bar Soloveychik            University of Minnesota  8:54.69\n",
       "20                   John Ehling               Princeton University  8:54.78\n",
       "21              Sasha Lyubavskiy                University of Texas  8:55.03\n",
       "22                Lucas Henveaux  University of California-Berkeley  8:55.20\n",
       "23                    Eric Brown              University of Florida  8:55.21\n",
       "24              Victor JOHANSSON              University of Alabama  8:55.65\n",
       "25               Cedric BUESSING         University of Indianapolis  8:55.88\n",
       "26                 Hayden Curley                University of Tampa  8:56.58\n",
       "27             Eduardo Cisternas      Pennsylvania State University  8:56.63\n",
       "28                    Owen Lloyd    North Carolina State University  8:56.87\n",
       "29                 Victor Rosado      Oklahoma Christian University  8:56.94\n",
       "30     Dylan Robert Porges Avila               Princeton University  8:57.14\n",
       "31                   Jack Little            University of Tennessee  8:57.56\n",
       "32                 Gio Linscheer              University of Florida  8:57.71\n",
       "33                 Jake Mitchell              University of Florida  8:57.74\n",
       "34                   Alex Zettle                University of Texas  8:57.84\n",
       "35                  Mason Edmund              Ohio State University  8:59.35\n",
       "36              Brice Barrieault       U.S. Military Academy (Army)  8:59.40\n",
       "37  Rafael Nicolas Ponce De Leon            University of Tennessee  8:59.69\n",
       "38               Brennan Gravley              University of Florida  8:59.75\n",
       "39                ILIA SIBIRTSEV           University of Louisville  8:59.92\n",
       "40                Michael Bonson                  Auburn University  9:00.05\n",
       "41                   Grant Davis                  Auburn University  9:00.06\n",
       "42                  Aidan Wilson                   Brown University  9:00.09\n",
       "43                Mark Kovacsics      California Baptist University  9:00.20\n",
       "44                Jack VanDeusen              University of Florida  9:00.23\n",
       "45                  Gabe MACHADO                Stanford University  9:00.41\n",
       "46                   Eric Hieber      Grand Valley State University  9:00.47\n",
       "47                Oskar Lindholm              University of Florida  9:00.49\n",
       "48                    Jake Mason           Arizona State University  9:00.79\n",
       "49                   Jake Narvid            University of Tennessee  9:01.02"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collegeSwimming('1000 Free')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5448ae29",
   "metadata": {},
   "source": [
    "### Q4.C.) Write a short paragraph about the businesses or research that would use the data you scraped. Descrivbe it's value and what it can be used for."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56fcd498",
   "metadata": {},
   "source": [
    "The function I wrote can go through an event and get the top 50 times for college swimming. The NCAA typically takes between 19-25 guys for an event, so a swimmer can see how close they would be to making NCAAs if they are on the bubble. The function could be expanded to go through all the years available to see how much faster swimmers have gotten, and to try to understand why swimmers may be getting faster, whether it is training or the swim suits available at the time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
